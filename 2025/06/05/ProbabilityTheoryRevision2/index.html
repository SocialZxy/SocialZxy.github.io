<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":"flat","style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Abstract. 前半部分是集中不等式、大数定律和中心极限定理。后半部分是无聊的统计。    准备工具 集中不等式 随机变量的收敛 特征函数   大数定律，中心极限定理 统计基础 参数估计 点估计的评价 点估计的方法 区间估计   假设检验 方差分析 回归分析 附录：统计常用速查表格">
<meta property="og:type" content="article">
<meta property="og:title" content="Revision | 信息科学中的概率统计（下）">
<meta property="og:url" content="http://example.com/2025/06/05/ProbabilityTheoryRevision2/index.html">
<meta property="og:site_name" content="Stellary&#39;s Notes">
<meta property="og:description" content="Abstract. 前半部分是集中不等式、大数定律和中心极限定理。后半部分是无聊的统计。    准备工具 集中不等式 随机变量的收敛 特征函数   大数定律，中心极限定理 统计基础 参数估计 点估计的评价 点估计的方法 区间估计   假设检验 方差分析 回归分析 附录：统计常用速查表格">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-06-05T05:23:42.000Z">
<meta property="article:modified_time" content="2025-06-14T09:03:44.357Z">
<meta property="article:author" content="King Strange">
<meta property="article:tag" content="Probability Theory">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2025/06/05/ProbabilityTheoryRevision2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2025/06/05/ProbabilityTheoryRevision2/","path":"2025/06/05/ProbabilityTheoryRevision2/","title":"Revision | 信息科学中的概率统计（下）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Revision | 信息科学中的概率统计（下） | Stellary's Notes</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Stellary's Notes</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-index"><a href="/index/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>index</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">1.</span> <span class="nav-text">准备工具</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.1.</span> <span class="nav-text">集中不等式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.2.</span> <span class="nav-text">随机变量的收敛</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">1.3.</span> <span class="nav-text">特征函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">2.</span> <span class="nav-text">大数定律，中心极限定理</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">3.</span> <span class="nav-text">统计基础</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">4.</span> <span class="nav-text">参数估计</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.1.</span> <span class="nav-text">点估计的评价</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.2.</span> <span class="nav-text">点估计的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">4.3.</span> <span class="nav-text">区间估计</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">5.</span> <span class="nav-text">假设检验</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">6.</span> <span class="nav-text">方差分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">7.</span> <span class="nav-text">回归分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link"><span class="nav-number">8.</span> <span class="nav-text">附录：统计常用速查表格</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="King Strange"
      src="https://s2.loli.net/2023/11/24/rtCEFG1igyYAlm4.png">
  <p class="site-author-name" itemprop="name">King Strange</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/SocialZxy" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SocialZxy" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:stellary@stu.pku.edu.cn" title="E-Mail → mailto:stellary@stu.pku.edu.cn" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          Links
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://hexo.io/" title="https:&#x2F;&#x2F;hexo.io" rel="noopener" target="_blank">Hexo</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://theme-next.js.org/" title="https:&#x2F;&#x2F;theme-next.js.org&#x2F;" rel="noopener" target="_blank">NexT</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://syksykccc.github.io/" title="https:&#x2F;&#x2F;syksykccc.github.io" rel="noopener" target="_blank">syksykCCC</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://blog.imyangty.com/" title="https:&#x2F;&#x2F;blog.imyangty.com" rel="noopener" target="_blank">YangTY's Blog - 越过山川</a>
            </li>
            <li class="links-of-blogroll-item">
              <a href="https://rpche-6626.github.io/" title="https:&#x2F;&#x2F;rpche-6626.github.io&#x2F;" rel="noopener" target="_blank">RPChe_6626</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/06/05/ProbabilityTheoryRevision2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://s2.loli.net/2023/11/24/rtCEFG1igyYAlm4.png">
      <meta itemprop="name" content="King Strange">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Stellary's Notes">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Revision | 信息科学中的概率统计（下） | Stellary's Notes">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Revision | 信息科学中的概率统计（下）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-05 13:23:42" itemprop="dateCreated datePublished" datetime="2025-06-05T13:23:42+08:00">2025-06-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-06-14 17:03:44" itemprop="dateModified" datetime="2025-06-14T17:03:44+08:00">2025-06-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Revision-Notes/" itemprop="url" rel="index"><span itemprop="name">Revision Notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><strong>Abstract.</strong> 前半部分是集中不等式、大数定律和中心极限定理。后半部分是无聊的统计。</p>
<!-- toc -->

<ul>
<li><a href="#%E5%87%86%E5%A4%87%E5%B7%A5%E5%85%B7">准备工具</a><ul>
<li><a href="#%E9%9B%86%E4%B8%AD%E4%B8%8D%E7%AD%89%E5%BC%8F">集中不等式</a></li>
<li><a href="#%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F%E7%9A%84%E6%94%B6%E6%95%9B">随机变量的收敛</a></li>
<li><a href="#%E7%89%B9%E5%BE%81%E5%87%BD%E6%95%B0">特征函数</a></li>
</ul>
</li>
<li><a href="#%E5%A4%A7%E6%95%B0%E5%AE%9A%E5%BE%8B%E4%B8%AD%E5%BF%83%E6%9E%81%E9%99%90%E5%AE%9A%E7%90%86">大数定律，中心极限定理</a></li>
<li><a href="#%E7%BB%9F%E8%AE%A1%E5%9F%BA%E7%A1%80">统计基础</a></li>
<li><a href="#%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1">参数估计</a><ul>
<li><a href="#%E7%82%B9%E4%BC%B0%E8%AE%A1%E7%9A%84%E8%AF%84%E4%BB%B7">点估计的评价</a></li>
<li><a href="#%E7%82%B9%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%96%B9%E6%B3%95">点估计的方法</a></li>
<li><a href="#%E5%8C%BA%E9%97%B4%E4%BC%B0%E8%AE%A1">区间估计</a></li>
</ul>
</li>
<li><a href="#%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C">假设检验</a></li>
<li><a href="#%E6%96%B9%E5%B7%AE%E5%88%86%E6%9E%90">方差分析</a></li>
<li><a href="#%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90">回归分析</a></li>
<li><a href="#%E9%99%84%E5%BD%95%E7%BB%9F%E8%AE%A1%E5%B8%B8%E7%94%A8%E9%80%9F%E6%9F%A5%E8%A1%A8%E6%A0%BC">附录：统计常用速查表格</a></li>
</ul>
<!-- tocstop -->

<span id="more"></span>

<h1><span id="准备工具">准备工具</span></h1><h2><span id="集中不等式">集中不等式</span></h2><div class="note info"><p><strong>定理 1.1.1（马尔可夫不等式）.</strong> 设随机变量的 $k$ 阶矩存在（$\mathbb{E}[|X|^k] &lt; \infty$），则</p>
<p>$$<br>\Pr[|X| &gt; \varepsilon] \leq \frac{\mathbb{E}[|X|^k]}{\varepsilon^k}<br>$$</p>
</div>

<p><strong>证明.</strong></p>
<p>$$<br>\begin{aligned}<br>    \Pr[|X| &gt; \varepsilon] &#x3D; \int_{|x| &gt; \varepsilon} f(x)\mathrm{d}x \leq \int_{|x| &gt; \varepsilon} \frac{|x|^k}{\varepsilon^k} f(x)\mathrm{d}x &#x3D; \frac{\mathbb{E}[|X|^k]}{\varepsilon^k}<br>\end{aligned}<br>$$</p>
<p>$\blacksquare$</p>
<div class="note info"><p><strong>定理 1.1.2（切比雪夫不等式）.</strong> 设随机变量的期望 $\mu$ 和方差 $\sigma^2$ 存在，则 </p>
<p>$$<br>\Pr(|X - \mu| &gt; \varepsilon) \leq \frac{\sigma^2}{\varepsilon^2}<br>$$</p>
</div>

<p><strong>证明.</strong> 对标准化后的随机变量使用二阶矩的马尔可夫不等式。$\blacksquare$</p>
<p>上面两个不等式都只考虑了随机变量的某一阶矩。可以想象的是，我们可以将所有阶矩通过某种方式混合起来考虑，然后通过调参找到最紧的一种混合方式。为此，引入矩生成函数</p>
<div class="note success"><p><strong>定义 1.1.1（矩生成函数）.</strong> 随机变量 $X$ 的矩生成函数是 $\mathrm{MGF}_X(t) &#x3D; \mathbb{E}[e^{tX}]$。</p>
</div>

<blockquote>
<p><strong>Remark 1.1.1.</strong> 关于这个东西的命名：矩生成函数正是随机变量各阶矩的 EGF。</p>
</blockquote>
<p>矩生成函数法系如下范式——证明 $\Pr[X &gt; \varepsilon]$ 的界可用如下步骤：</p>
<ol>
<li>注意 $X &gt; \varepsilon$ 等价于 $e^{tX} &gt; e^{t\varepsilon}$；</li>
<li>使用马尔可夫不等式，导出概率不超过 $\mathbb{E}[e^{tX}] &#x2F; e^{t\varepsilon} \leq \varphi(t)$；</li>
<li>求 $t$ 使得 $\varphi(t)$ 最小化，即得到概率上界为 $\varphi(t^*)$。</li>
</ol>
<div class="note info"><p><strong>定理 1.1.3（Chernoff 界）.</strong> 设 $X_1, X_2, …, X_n$ 独立，$X_i\sim \mathrm{Bern}(p_i)$，$p &#x3D; \frac 1n \sum_{i&#x3D;1}^n p_i$，则对于任意 $\varepsilon &gt; 0$ 都有</p>
<p>$$<br>\Pr\left[\frac 1n\sum_{i&#x3D;1}^n X_i \geq p + \varepsilon\right] &lt; \mathbb{e}^{-nD(p + \varepsilon\Vert p)} \leq e^{-2n\varepsilon^2}<br>$$</p>
</div>

<p><strong>证明.</strong> 标准的矩生成函数法。记 $X &#x3D; \sum_{i&#x3D;1}^n X_i$</p>
<p>$$<br>\begin{aligned}<br>\Pr[X \geq n(p + \varepsilon)]&amp;\leq \frac{\mathbb{E}[e^{tX}]}{e^{tn(p + \varepsilon)}} &amp;{\color{blue}\text{Markov bound}} \\<br>&amp;&#x3D;\frac{\prod_{i&#x3D;1}^n(1 - p_i + p_ie^{t})}{e^{tn(p + \varepsilon)}} &amp;{\color{blue}{\text{Independentness}}} \\<br>&amp;\leq \frac{(1 - p + pe^{t})^n}{e^{tn(p + \varepsilon)}} &amp;{\color{blue}{\text{$\text{AM} \geq \text{GM}$ Inequality}}}<br>\end{aligned}<br>$$</p>
<p>只需最小化 $\ln(1 - p + p\varepsilon^t) - t(p + \varepsilon)$。简单求导可知 $t &#x3D; \ln \frac{(p + \varepsilon)(1 - p)}{(1 - p - \varepsilon)p}$ 时恰好是 $D(p + \varepsilon \Vert p)$。</p>
<p>还可以根据经典不等式 $D(p \Vert q) \geq 2\Delta_{TV}(p, q)^2$ 再放缩一次。$\blacksquare$</p>
<p>注意，Chernoff 界可以加强至任意 $[0, 1]$ 上的分布。因为根据 Jensen 不等式</p>
<p>$$<br>\mathbb{E}[e^{tX}] \leq 1 - p + p{e^t}<br>$$</p>
<p>上述矩生成函数方法仍然成立。</p>
<p>对于更一般的分布，可以使用 Azuma-Hoeffding 不等式。</p>
<div class="note info"><p><strong>引理 1.1.4（Hoeffding 引理）.</strong> 随机变量 $X\in [a, b], \mathbb{E}[X] &#x3D; 0$，则 $\mathbb{E}[e^{tX}] \leq \exp\left(\frac{t^2(b - a)^2}{8}\right)$</p>
</div>

<p><strong>证明.</strong> 这个式子很像我们证 Azuma 不等式的时候证的东西，但是它不对称，所以阴间了很多（因为 $e^x$ 的性质，哪怕是将区间向左平移一下都会让不等式松很多）。</p>
<p>首先用 Jensen 不等式，可知 </p>
<p>$$<br>\mathbb{E}[e^{tX}] \leq \mathbb{E}\left[\frac{X - a}{b - a}e^{tb} + \frac{b - X}{b - a}e^{ta}\right] \leq \frac{-a}{b - a}e^{tb} + \frac{b}{b - a}e^{ta}<br>$$</p>
<p>将右侧式子取对数后泰勒展开到二阶拉格朗日余项即可证明。节约时间这里略去。$\blacksquare$</p>
<div class="note info"><p><strong>定理 1.1.5（Azuma-Hoeffding 不等式）.</strong> 随机变量 $X_1, …, X_n$ 相互独立，期望均为 $0$，各自有上下界 $a_i, b_i$（$\forall i, X_i\in [a_i, b_i]$），则对于任意的 $\varepsilon &gt; 0$</p>
<p>$$<br>\begin{align}<br>\Pr\left[\sum_{i&#x3D;1}^n X_i &gt; \varepsilon\right] \leq \exp\left(-\frac{2\varepsilon^2}{\sum_{i&#x3D;1}^n (a_i - b_i)^2}\right) \\<br>\Pr\left[\sum_{i&#x3D;1}^n X_i &lt; -\varepsilon\right] \leq \exp\left(-\frac{2\varepsilon^2}{\sum_{i&#x3D;1}^n (a_i - b_i)^2}\right)<br>\end{align}<br>$$</p>
</div>

<p><strong>证明.</strong> 我们只需要证明 $&gt; \varepsilon$ 的一边，另一边取相反数即可得证。</p>
<p>记 $X &#x3D; \sum_{i&#x3D;1}^n X_i$。则对于任意的 $t &gt; 0$，$X &gt; \varepsilon$ 等价于 $e^{tX} &gt; e^{t\varepsilon}$。依次根据马尔可夫不等式、变量独立性、Hoeffding 引理</p>
<p>$$<br>\begin{aligned}<br>\mathrm{LHS} &amp;\leq \frac{\mathbb{E}[e^{tX}]}{e^{t\varepsilon}} &#x3D; \frac{\prod_{i&#x3D;1}^n\mathbb{E}[e^{tX_i}]}{e^{t\varepsilon}} \leq \exp\left(t^2\sum_{i&#x3D;1}^n \frac{(a_i - b_i)^2}{8} - \varepsilon t\right)<br>\end{aligned}<br>$$</p>
<p>取 $t &#x3D; 4 &#x2F; \sum_{i&#x3D;1}^n (a_i - b_i)^2$ 得到最紧的上界。$\blacksquare$</p>
<p>证明的重点是一个 Hoeffding 引理的成立性，因此可以定义</p>
<div class="note success"><p><strong>定义 1.1.2（Subgaussian 分布）.</strong> 对于随机变量 $X$，若 $\forall t\in \mathbb{R}, \mathrm{MGF}_X(t) \leq e^{\frac{\sigma^2t^2}{2}}$，则称 $X$ 是 $\sigma$-subgaussian 的。</p>
</div>

<blockquote>
<p><strong>Remark.</strong> 不等号右侧是 $\mathcal{N}(0, \sigma^2)$ 的矩生成函数。正态分布的尾分布有指数级的上界：</p>
<p>$$<br>\Pr[X &gt; t] &#x3D; \int_{t}^\infty \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{x^2}{2\sigma^2}}\mathrm{d}x \leq \int_{t}^\infty \frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{t^2 + (x - t)^2}{2\sigma^2}} \mathrm{d}x &#x3D; \frac 12 e^{-\frac{t^2}{2\sigma^2}}<br>$$</p>
</blockquote>
<p>实际上 Hoeffding 不等式可以加强成：若 $X_i$ 都是 $\sigma_i$-subgaussian 分布，则 </p>
<p>$$<br>\Pr\left[\sum_{i&#x3D;1}^n X_i &gt; \varepsilon\right] \leq \exp\left(-\frac{\varepsilon^2}{2\sum_{i&#x3D;1}^n \sigma_i^2}\right)<br>$$</p>
<p>可以证明关于 Subgaussian 分布的一些性质。</p>
<div class="note info"><p><strong>定理 1.1.6（Subgaussian 分布的性质）</strong> 若 $X, X_1, X_2$ 是 $\sigma, \sigma_1, \sigma_2$-subgaussian 分布，则以下断言成立：</p>
<ol>
<li>$\mathbb{E}[X] &#x3D; 0, \mathbb{D}(X) \leq \sigma^2$；</li>
<li>$cX$ 是 $|c|\sigma$-subgaussian 分布；</li>
<li>$X_1 + X_2$ 是 $\sqrt{\sigma_1^2 + \sigma_2^2}$-subgaussian 分布。</li>
</ol>
</div>

<p><strong>证明.</strong> 在 $t &#x3D; 0$ 处的端点效应（$t &#x3D; 0$ 时两函数相等，为了保证全局小于等于需要导数相等，二阶导不超过 $\sigma^2$）蕴含断言 1。</p>
<p>后面两个断言是平凡的。$\blacksquare$</p>
<p>对于一些非 subgaussian 的分布，比如 $\Gamma$ 分布和 $\chi^2$ 分布，也可以用矩生成函数方法得到集中不等式。计算机科学中两个经典的例子是 Coupon Collector Bound 和 Johnson-Lindstrauss Lemma，想必大家都非常熟悉。</p>
<h2><span id="随机变量的收敛">随机变量的收敛</span></h2><p>本节形式化定义高中概率统计中常见的“频率收敛于概率 &#x2F; 均值收敛于期望 &#x2F; 几乎是正态分布”一类的说法。共有三种想法：</p>
<ol>
<li>随着试验次数的增加，高概率观测到实验结果和 $X$ 的误差不大。<strong>（依概率收敛）</strong></li>
<li>随着试验次数的增加，实验结果的分布和 $X$ 的分布误差不大。<strong>（依分布收敛）</strong></li>
<li>如果做无穷次实验，几乎必然观测到实验结果就是 $X$。<strong>（几乎必然收敛）</strong></li>
</ol>
<div class="note success"><p><strong>定义 1.2.1（依概率收敛）.</strong> 考虑随机变量 $X, X_1, X_2, …$，若对于任意的 $\varepsilon &gt; 0$ 都有 </p>
<p>$$<br>\lim_{n\rightarrow \infty} \Pr[|X_n - X| &lt; \varepsilon] &#x3D; 1<br>$$</p>
<p>则称随机变量序列 $X_1, X_2, …$ 依概率收敛于 $X$，记作 $X_n \xrightarrow{P} X (n\rightarrow \infty)$。</p>
</div>

<div class="note success"><p><strong>定义 1.2.2（依分布收敛）.</strong> 考虑随机变量 $X, X_1, X_2, …$，若 $X_n$ 的分布函数在 $X$ 的一切连续点上点点收敛于 $X$ 的分布函数，i.e.</p>
<p>$$<br>\lim_{n\rightarrow \infty} F_{X_n}(X) &#x3D; F_X(x)<br>$$</p>
<p>则称 $\{F_{X_n}(x)\}$ 弱收敛于 $F_{X}(x)$，或随机变量列 $X_1, X_2, …$ 依分布收敛于 $X$，记作 $X_n\xrightarrow{d} X (n\rightarrow \infty)$。</p>
</div>

<blockquote>
<p><strong>Remark 1.2.1.</strong> 在正经的概率论教材中，应该会把范围扩大到非降函数 $F(X)$，比如说 $X_i &#x3D; i$ 的分布函数弱收敛到 $0$。但这里我们不管。</p>
</blockquote>
<div class="note success"><p><strong>定义 1.2.3（几乎必然收敛）.</strong> 考虑随机变量 $X, X_1, X_2, …$，若 </p>
<p>$$<br>\Pr\left[\lim_{n\rightarrow \infty} X_n &#x3D; X\right] &#x3D; 1<br>$$</p>
<p>则称 $\{X_n\}$ 几乎必然收敛于 $X$，记作 $X_n\xrightarrow{a.s.} X (n\rightarrow \infty)$。</p>
</div>

<blockquote>
<p><strong>Remark 1.2.2.</strong> 依分布收敛和几乎必然收敛的定义可能显得比较怪。需要时刻记住随机变量是 $\mathcal{S}\rightarrow \mathbb{R}$ 的可测函数，随机变量的背后都是有一个样本空间的。实验结果是这个样本空间中的一个样本，$X_n$ 只是它的函数值。</p>
</blockquote>
<div class="note info"><p><strong>定理 1.2.1（几乎必然收敛的刻画）.</strong> 令事件 $A_n(\varepsilon) &#x3D; \{|X_n - X| \geq \varepsilon\}$，则 $X_n \xrightarrow{a.s.} X$ 当且仅当</p>
<p>$$<br>\forall \varepsilon &gt; 0, \lim_{n\rightarrow \infty} \Pr\left[\bigcup_{m &#x3D; n}^\infty A_m(\varepsilon)\right] &#x3D; 0 \label{as-eqdef}<br>$$</p>
</div>

<p><strong>证明.</strong> 用 $\varepsilon &#x3D; 1 &#x2F; k$ 控制极限，将几乎必然收敛的定义改写做</p>
<p>$$<br>\Pr\left[\bigcap_{k&#x3D;1}^\infty\bigcup_{n &#x3D; 1}^\infty \bigcap_{m &#x3D; n}^\infty \neg A_m(1 &#x2F; k)\right] &#x3D; 1 \quad\Leftrightarrow\quad \Pr\left[\bigcup_{k&#x3D;1}^\infty\bigcap_{n &#x3D; 1}^\infty \bigcup_{m &#x3D; n}^\infty A_m(1 &#x2F; k)\right] &#x3D; 0<br>$$</p>
<p>根据次可加性、单调性，上式等价于 </p>
<p>$$<br>\forall k\in \mathbb{N}, \Pr\left[\bigcap_{n &#x3D; 1}^\infty \bigcup_{m &#x3D; n}^\infty A_m(1 &#x2F; k)\right] &#x3D; 0 \label{1.2.1-inter1}<br>$$</p>
<p>进而可推出 $\forall \varepsilon &gt; 0$ 上式都成立（将 $\varepsilon$ round 到不超过它的某个 $1&#x2F;k$，注意 $A_m(x)$ 关于 $x$ 不升）。$(\ref{1.2.1-inter1})\Leftrightarrow (\ref{as-eqdef})$ 无非是因为 $\cup_{m &#x3D; n}^\infty A_m(\varepsilon)$ 是单调的。$\blacksquare$</p>
<blockquote>
<p><strong>Remark 1.2.3.</strong> 依概率收敛的定义是 $\lim_{n\rightarrow \infty} A_n(\varepsilon) &#x3D; 0$。</p>
</blockquote>
<div class="note info"><p><strong>定理 1.2.2.</strong> 几乎必然收敛蕴含依概率收敛，反之未必（<em>即使是收敛到常数分布也不行</em>）。</p>
</div>

<p><strong>证明.</strong> 因为 $A_n(\varepsilon) \subseteq \cup_{m&#x3D;n}^\infty A_n(\varepsilon)$。此外，我们给出一个逆命题的反例。</p>
<p>考虑一列独立的随机变量，$X_i\sim \mathrm{Bern}(1 &#x2F; i)$。计算发现这列随机变量依概率收敛至 $0$，但是不可能几乎必然收敛。$\blacksquare$</p>
<div class="note info"><p><strong>定理 1.2.3.</strong> 依概率收敛蕴含依分布收敛，反之未必。</p>
</div>

<p><strong>证明.</strong> 用几个连续性立即得证。逆命题不成立的本质原因是分布相同不能推出随机变量相同（除非该分布是常数分布）。$\blacksquare$</p>
<h2><span id="特征函数">特征函数</span></h2><p>我们经常遇到计算两个随机变量之和 $X_1 + X_2$ 的密度函数的问题。熟知，这个问题的答案是两个函数概率密度函数的卷积。因此，我们想到可以用傅里叶变换来计算卷积。</p>
<div class="note danger"><p><strong>警告.</strong> 因为我是学计算机的，所以将省略一切分析上的严格推导。</p>
</div>

<div class="note success"><p><strong>定义 1.3.1（特征函数）.</strong> 定义随机变量 $X$ 的特征函数为</p>
<p>$$<br>\psi_X(t) :&#x3D; \mathbb{E}[e^{itX}]<br>$$</p>
<p>这正是 $X$ 的密度函数的傅里叶变换。</p>
</div>

<div class="note info"><p><strong>命题 1.3.2（特征函数的性质）.</strong> 关于特征函数，有如下简单的性质：</p>
<ol>
<li>$\psi_{aX + b}(t) &#x3D; e^{itb}\psi_X(at)$；</li>
<li>若 $X_1, X_2$ 独立，则 $\psi_{X_1 + X_2} &#x3D; \psi_{X_1}(t)\psi_{X_2}(t)$；</li>
<li>可以从特征函数中提取 $X$ 的 $k$ 阶矩：$\mathbb{E}[X^k] &#x3D; (-i)^k \psi_X^{(k)}(0)$。</li>
</ol>
</div>

<p><strong>证明.</strong> 直接对着定义验证即可。第三个断言可能需要一些积分和求导的交换性，这里没办法，只能不管。$\blacksquare$</p>
<p>关于特征函数有两个重要结论，但是没学过实分析，只能不证。</p>
<div class="note info"><p><strong>定理 1.3.3（唯一性定理）.</strong> 随机变量的分布函数由特征函数唯一决定。</p>
</div>

<div class="note info"><p><strong>定理 1.3.4（连续性定理）.</strong> 分布函数 $F_{X_n}$ 弱收敛于 $F_X$ 的充分必要条件是 $\psi_{X_n}$ 点点收敛于 $\psi_X$。</p>
</div>

<h1><span id="大数定律中心极限定理">大数定律，中心极限定理</span></h1><p>关于依概率收敛的几个大数定律称作弱大数定律。在几种不同的独立性要求下，都可以证明均值收敛于期望。</p>
<div class="note info"><p><strong>定理 2.1（切比雪夫大数定律）.</strong> 设随机变量 $X_1, X_2, …$ 两两独立，方差都有界，则对于任意的 $\varepsilon &gt; 0$ 都有 </p>
<p>$$<br>\lim_{n\rightarrow \infty} \Pr\left[\left|\frac{\sum_{i&#x3D;1}^n X_i}{n} - \frac{\sum_{i&#x3D;1}^n \mathbb{E}[X_i]}{n}\right| &lt; \varepsilon\right] &#x3D; 1<br>$$</p>
</div>

<p><strong>证明.</strong> 假设方差上界是 $C$，则由切比雪夫不等式可知偏差超过 $\varepsilon$ 不超过 $C &#x2F; n\varepsilon^2$，因此收敛于 $0$。$\blacksquare$</p>
<div class="note info"><p><strong>定理 2.2（马尔可夫大数定律）.</strong> 设随机变量 $X_1, X_2, …$ 两两独立，且 $\lim_{n\rightarrow\infty} \frac{1}{n^2}\sum_{i&#x3D;1}^n D(X_i) &#x3D; 0$，则</p>
<p>$$<br>\lim_{n\rightarrow \infty} \Pr\left[\left|\frac{\sum_{i&#x3D;1}^n X_i}{n} - \frac{\sum_{i&#x3D;1}^n \mathbb{E}[X_i]}{n}\right| &lt; \varepsilon\right] &#x3D; 1<br>$$</p>
</div>

<p><strong>证明.</strong> 仍然是切比雪夫不等式。$\blacksquare$</p>
<div class="note info"><p><strong>定理 2.3（辛钦大数定律）.</strong> 设随机变量 $X_1, X_2, …$ 独立同分布，且期望 $\mu$ 存在，则对于任意的 $\varepsilon &gt; 0$ 都有</p>
<p>$$<br>\lim_{n\rightarrow \infty} \Pr\left[\left|\frac{\sum_{i&#x3D;1}^n X_i}{n} - \mu\right| &lt; \varepsilon\right] &#x3D; 1<br>$$</p>
</div>

<p><strong>证明.</strong> 这里关于随机变量的矩没有什么信息，因此不能继续用之前常用的矩方法。考虑使用特征函数。</p>
<p>依概率收敛于常数等价于依分布收敛进而等价于特征函数点点收敛，考虑证明之。若 $X_i$ 的特征函数是 $\psi_{X_i}(t)$（因为独立同分布所以均相等），则 $X &#x3D; \frac 1n \sum_{i&#x3D;1}^n X_i$ 的特征函数是 $\psi_{X_i}(t&#x2F;n)^n$。对于固定的 $t$，有在零处的泰勒展开（带 Peano 余项）</p>
<p>$$<br>\psi_{X_i}(t) &#x3D; 1 + t\cdot \psi_{X_i}’(t) + o(t^2) &#x3D; 1 + i\mu t + o(t^2)<br>$$</p>
<p>因此 </p>
<p>$$<br>\psi_{X_i}(t &#x2F; n)^n &#x3D; \left(1 + \frac{i\mu t}{n} + o(t^2 &#x2F; n)\right)^n \rightarrow e^{i\mu t} \quad (n\rightarrow \infty)<br>$$</p>
<p>因此依分布收敛于常数分布 $\mu$，根据唯一性定理，定理得证。$\blacksquare$</p>
<p>几乎必然收敛意义下的大数定律称作强大数定律。现在要将 $A_n(\varepsilon)$ 加强至 $\cup_{m&#x3D;n}^\infty A_n(\varepsilon)$，最简单粗暴的办法是拓展切比雪夫大数定律，将有界矩的阶数加到四阶。</p>
<div class="note info"><p><strong>定理 2.4（强大数定律）.</strong> 设 $X_1, X_2, …$ 独立同分布，期望存在（最弱可以是 $4$-wise 独立，期望存在），且 $\mathbb{E}[X_i^4] \leq C$。令 $S_n$ 是前 $n$ 个随机变量之和，则</p>
<p>$$<br>\frac{S_n - \mathbb{E}(S_n)}{n} \xrightarrow{a.s.} 0 \quad(n\rightarrow \infty)<br>$$</p>
</div>

<p><strong>证明.</strong> 用四阶矩方法可以证明 $A_m(\varepsilon) \leq \mathbb{E}(S^4_m) &#x2F; {n^4\varepsilon^4}$，注意</p>
<p>$$<br>\begin{aligned}<br>\mathbb{E}[S_m^4] &amp;&#x3D; \sum_{i, j, k, l} \mathbb{E}[X_i X_j X_k X_l] \\<br>                  &amp;&#x3D; {\sum_{i&#x3D;1}^m \mathbb{E}[X_i^4]} + {6 \sum_{i &lt; j}\mathbb{E}[X^2_i]\mathbb{E}[X^2_j]} \\<br>                  &amp;\leq mC + 6m^2C<br>\end{aligned}<br>$$</p>
<p>这里使用了柯西不等式：$\mathbb{E}[X^2] \leq \sqrt{\mathbb{E}[1]} \cdot \sqrt{\mathbb{E}[X^4]}$ 因此 </p>
<p>$$<br>\Pr\left[\cup_{m&#x3D;n}^\infty A_m(\varepsilon)\right] \leq \sum_{m &#x3D; n}^\infty A_{m}(\varepsilon) \leq \sum_{m &#x3D; n}^\infty O\left(\frac{1}{m^2}\right) &#x3D; O\left(\frac{1}{n^2}\right)<br>$$</p>
<p>根据定理 1.2.1 定理得证。$\blacksquare$</p>
<div class="note info"><p><strong>定理 2.5（Kolmogrov 大数定律）</strong> 设 $X_1, X_2, …$ 独立同分布，期望、方差存在，则 </p>
<p>$$<br>\frac{S_n}{n} \xrightarrow{a.s.} \mathbb{E}[X]<br>$$</p>
</div>

<blockquote>
<p><strong>Remark 2.1.</strong> 在正经的概率论教材中这个定理的叙述可能是，存在一列单增趋于无穷的 $b_n$ 使得 $\sum_{i&#x3D;1}^n D[X_n] &#x2F; b_n^2$ 收敛推出 $S_n &#x2F; b_n$ 几乎必然收敛。我们写的只是令 $b_n &#x3D; n$ 的特殊情况。</p>
</blockquote>
<blockquote>
<p><strong>Remark 2.2.</strong> 证明这个定理需要很多我不想写的前置知识（比如几乎必然收敛的柯西准则、Kronecker 引理等），所以这里不证。</p>
</blockquote>
<hr>
<p>如果你现在不是除 $n$ 而是除 $\sqrt n$，就会使得 $D[S_n &#x2F; \sqrt n] &#x3D; D(X)$，因此，$S_n &#x2F; \sqrt n$ 不会收敛到一个点上，但是中心极限定理指出它将收敛于正态分布。</p>
<div class="note info"><p><strong>定理 2.6（Lindeberg-Lévy 中心极限定理）.</strong> 设 $X_1, X_2, …$ 独立同分布，$\mathbb{E}[X_i] &#x3D; \mu, D[X_i] &#x3D; \sigma^2$，令</p>
<p>$$<br>\widetilde{S}_n &#x3D; \frac{\sum_{i&#x3D;1}^n X_i - \mu}{\sqrt n\sigma}<br>$$</p>
<p>则 $\widetilde{S}_n \xrightarrow{d} Z\sim \mathcal{N}(0, 1)$。</p>
</div>

<p><strong>证明.</strong> 不失一般性设 $\mu &#x3D; 0, \sigma &#x3D; 1$，考虑 $\sum_{i&#x3D;1}^n X_i &#x2F; \sqrt n$ 的特征函数：</p>
<p>$$<br>\psi_{\widetilde{S}_n}(t) &#x3D; \psi_{X}(t &#x2F; \sqrt n)^n<br>$$</p>
<p>将 $\psi_{X}(t)$ 泰勒展开到二阶 Peano 余项得到</p>
<p>$$<br>\psi_{X}(t) &#x3D; 1 + i \mathbb{E}[X] t - D[X] \frac{t^2}{2} + o(t^2) &#x3D; 1 - \frac{t^2}{2} + o(t^2)<br>$$</p>
<p>代入得到</p>
<p>$$<br>\psi_{\widetilde{S}_n}(t) &#x3D; \left(1 - \frac{t^2}{2n} + o\left(\frac{t^2}{n}\right)\right)^n \rightarrow e^{-t^2 &#x2F; 2}<br>$$</p>
<p>这正是 $\mathcal{N}(0, 1)$ 的特征函数。$\blacksquare$</p>
<p>中心极限定理的经典应用是用来估计 $n$ 比较大时的二项分布等。估计的误差由 Berry-Esseen 定理给出，但是我不会证，只在这里放一下形式：</p>
<div class="note info"><p><strong>定理 2.7（Berry-Esseen 中心极限定理）.</strong> 在中心极限定理的条件下，实际上有 </p>
<p>$$<br>\sup_{t\in \mathbb{R}} \left(\left|\Pr[\widetilde{S}_n &lt; t] - \Pr[Z &lt; t]\right|\right) &#x3D; O\left(\frac{\rho}{\sqrt n}\right)<br>$$</p>
<p>其中 $\rho &#x3D; \mathbb{E}[|X^3|]$。</p>
</div>

<p>一个有意思的应用是证明泊松分布的中位数基本上是在期望附近的，或者说 $X_n\sim \pi(n)$</p>
<p>$$<br>\lim_{n\rightarrow \infty} \Pr[X_n &lt; n] &#x3D; \lim_{n\rightarrow \infty} e^{-n}\sum_{i&#x3D;0}^n \frac{n^{i}}{i!} &#x3D; \frac 12<br>$$</p>
<p>方法是注意到 $X_n &#x3D; \sum_{i&#x3D;1}^n Y_i$，其中 $Y_i\sim \pi(1)$，然后用中心极限定理。误差也可以用 Berry-Esseen 给出，结论是 $\forall n, X\sim \pi(n)$ 则 $\Pr[X \leq n] \geq \frac 14$ 且 $\Pr[X\geq n] \geq \frac 14$。</p>
<h1><span id="统计基础">统计基础</span></h1><ul>
<li><strong>总体.</strong> 研究对象的全体。</li>
<li><strong>个体.</strong> 组成总体的每一成员。</li>
<li><strong>随机抽样.</strong> 从总体中等概率随机取 $n$ 个个体 $X_1, …, X_n$。$n$ 称作样本容量。</li>
<li><strong>样本空间.</strong> $X_1, …, X_n$ 可能取值构成的集合。’</li>
<li><strong>简单随机样本.</strong> $n$ 个独立同分布的随机样本。</li>
<li><strong>经验分布函数.</strong> 基于采样结果给出的分布函数的估计。设 $x_1, .., x_n$ 是取自分布为 $F(x)$ 的总体的简单随机样本（已经排序，i.e. $x_i \leq x_{i + 1}$），则 $F_n(x) &#x3D; k&#x2F;n (x_k\leq x \leq x_{k + 1})$（严谨起见，补充规定 $x_0 &#x3D; -\infty, x_{n + 1} &#x3D; \infty$）。</li>
<li><strong>统计量.</strong> 样本的非参数化的函数。</li>
</ul>
<p>介绍几个经典的统计量。</p>
<ul>
<li><strong>样本期望.</strong> $\bar{X} :&#x3D; \frac 1n\sum_{i&#x3D;1}^n x_i$；</li>
<li><strong>样本方差.</strong> $S^2 :&#x3D; \frac{1}{n - 1}\sum_{i&#x3D;1}^n (x_i - \bar{X})^2$；</li>
<li><strong>$k$ 阶（原点）矩.</strong> $A_k :&#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n x_i^k$；</li>
<li><strong>$k$ 阶中心矩.</strong> $B_k :&#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n (x_i - \bar{X})^k$。</li>
</ul>
<p>注意样本方差除的是 $n - 1$，和习惯不符。但是这样构造的统计量才是总体方差的无偏估计。验证在下方（事实 1）给出。</p>
<p>以下三个概率分布是统计中十分常用的。</p>
<div class="note success"><p><strong>定义 1（$\chi^2$ 分布）.</strong> 设 $X_1, …, X_n$ 独立服从分布 $\mathcal{N}(0, 1)$，则称 $\chi^2_n &#x3D; \sum_{i&#x3D;1}^n X_i^2$ 服从的分布为自由度为 $n$ 的 $\chi^2$ 分布（$\chi^2_n \sim \chi^2(n)$）。其概率密度为</p>
<p>$$<br>f_n(y) &#x3D; \begin{cases}<br>    \frac{1}{2^{n &#x2F; 2}\Gamma(n &#x2F; 2)}(y)^{\frac{n}{2} - 1}e^{-\frac{y}{2}} &amp; y &gt; 0 \\<br>    0 &amp; y \leq 0<br>\end{cases}<br>$$</p>
</div>

<p>为了验证其概率密度确实如是，惟须施归纳于 $n$，由于过于琐碎，此处略去。关于 $\chi^2$ 分布的一些事实：</p>
<ol>
<li>$\chi^2_n \sim \Gamma(n &#x2F; 2, 1 &#x2F; 2)$；</li>
<li>$\mathbb{E}[\chi^2_n] &#x3D; n, D[\chi^2_n] &#x3D; 2n$；</li>
<li>$\chi^2_n + \chi^2_m \sim \chi^2(n + m)$；</li>
<li>设 $\chi_\alpha^2(n)$ 为自由度为 $n$ 的 $\chi^2$ 分布的上 $\alpha$ 分位数，即 $\Pr[\chi^2 &gt; \chi^2_\alpha(n)] &#x3D; \alpha$ 的解。有 $n$ 足够大时（$ &gt; 40$），$\chi_\alpha^2(n)\approx \frac{1}{2}(z_{\alpha} + \sqrt{2n - 1})^2$。</li>
</ol>
<p>事实 $4$ 的证明可以参考 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/628970264">https://zhuanlan.zhihu.com/p/628970264</a> ，不太像常人所能现场证明的，恐须记住结论。</p>
<div class="note success"><p><strong>定义 2（$t$ 分布）.</strong> 设 $X\sim \mathcal{N}(0, 1), Y\sim \chi^2(n)$ 相互独立。则称 $T :&#x3D; \frac{X}{\sqrt{Y &#x2F; n}}$ 服从的分布为自由度为 $n$ 的 $t$ 分布（$T\sim t(n)$）。其密度函数为 </p>
<p>$$<br>f(t; n) &#x3D; \frac{\Gamma\left(\frac{n + 1}{2}\right)}{\sqrt{n\pi}\Gamma\left(\frac{n}{2}\right)}\left(1 + \frac{t^2}{n}\right)^{-\frac{n + 1}{2}}<br>$$</p>
</div>

<ol>
<li>当 $n$ 较大时，$t$ 分布近似为正态分布。</li>
<li>当 $n$ 较大时，其 $\alpha$ 上分位数 $t_{\alpha}$ 可以用 $z_{\alpha}$ 近似。</li>
</ol>
<div class="note success"><p><strong>定义 3（$F$ 分布）.</strong> 设 $X\sim \chi^2(n_1), Y\sim \chi^2(n^2)$ 相互独立，则称 $F &#x3D; \frac{X &#x2F; n_1}{Y &#x2F; n_2}$ 服从的分布为自由度为 $n_1, n_2$ 的 $F$ 分布（$F\sim F(n_1, n_2)$）。其密度函数为</p>
<p>$$<br>f(x; n_1, n_2) &#x3D; \begin{cases}<br>    \frac{1}{B(n_1 &#x2F; 2, n_2 &#x2F; 2)}n_1^{n_1 &#x2F; 2}n_2^{n_2 &#x2F; 2}x^{n_1 &#x2F; 2 - 1}(n_2 + n_1 x)^{-\frac{n_1 + n_2}{2}} &amp; x &gt; 0 \\<br>    0 &amp; x\leq 0<br>\end{cases}<br>$$</p>
</div>

<p>课件教的性质不是非常平凡就是没什么用。</p>
<ol>
<li>$F\sim F(n_1, n_2)\Rightarrow F^{-1}\sim F(n_2, n_1)$；</li>
<li>$X\sim t(n)\Rightarrow X^2\sim F(1, n)$；</li>
<li>$F_{1 - \alpha}(n_1, n_2) &#x3D; \frac{1}{F_{\alpha}(n_2, n_1)}$。</li>
</ol>
<p>为了建立关于统计的直觉，我们证明如下事实：</p>
<div class="note info"><p><strong>事实 1.</strong> $\mathbb{E}[S^2] &#x3D; D(X)$；</p>
</div>

<p><strong>验证.</strong></p>
<p>$$<br>\begin{aligned}<br>    \mathbb{E}[S^2] &amp;&#x3D; \frac{1}{n - 1}\mathbb{E}\left[\sum_{i&#x3D;1}^n x_i^2 - n\left(\frac{\sum_{i&#x3D;1}^n x_i}{n}\right)^2\right] \\<br>    &amp;&#x3D;\frac{1}{n - 1}\left(\frac{n - 1}{n}\sum_{i&#x3D;1}^n\mathbb{E}[x_i^2] - \frac{1}{n}\sum_{i\ne j}\mathbb{E}[x_i]\mathbb{E}[x_j]\right) \\<br>    &amp;&#x3D; \frac{1}{n - 1}\left((n - 1)\mathbb{E}[X^2] - (n - 1)\mathbb{E}[X]^2\right) &#x3D; D[X]<br>\end{aligned}<br>$$</p>
<p>这表明样本方差，确实应当除以 $n - 1$ 才能得到总体方差的无偏估计。$\blacksquare$</p>
<div class="note info"><p><strong>事实 2.</strong> $\bar{X}$ 和 $S^2$ 独立。</p>
</div>

<p><strong>证明.</strong> $(n - 1)S$ 是一个关于 $\boldsymbol{X}$ 的二次型。其矩阵表示为 </p>
<p>$$<br>\mathbf{A} &#x3D; \begin{pmatrix}<br>    \frac{n - 1}{n} &amp; -\frac{1}{n} &amp; \cdots &amp; -\frac{1}{n} \\<br>    -\frac{1}{n} &amp; \frac{n - 1}{n} &amp; \cdots &amp; -\frac{1}{n} \\<br>    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\<br>    -\frac{1}{n} &amp; -\frac{1}{n} &amp; \cdots &amp; \frac{n - 1}{n}<br>\end{pmatrix}<br>$$</p>
<p>考虑如何将其正交对角化。首先观察矩阵，发现 $\mathbf{A} - \mathbf{I}$ 是一个秩为 $1$ 的矩阵，所以矩阵有 $n - 1$ 个特征值都是 $1$。关于剩下的那个特征值是多少，可以用 trace trick 或者观察到 $(1, 1, …, 1)$ 是其一个特征向量来得到——无非是 $0$。</p>
<p>因此，如果我们将其正交对角化，所使用的正交矩阵形如</p>
<p>$$<br>\mathbf{P} &#x3D; \begin{pmatrix}<br>    \frac{1}{\sqrt n}\mathbf{1} \\<br>    \mathbf{P’}<br>\end{pmatrix}<br>$$</p>
<p>用 $\mathbf{P}$ 对 $\boldsymbol{X}$ 做坐标变换，得到 </p>
<p>$$<br>\mathbf{Y} &#x3D; \mathbf{P}\boldsymbol{X} &#x3D; \begin{pmatrix}<br>    \bar{X} \\<br>    \varepsilon_2 \\<br>    \vdots \\<br>    \varepsilon_n<br>\end{pmatrix}, \quad (n - 1)S^2 &#x3D; \boldsymbol{Y}^\top \begin{pmatrix}<br>    0 &amp;  &amp;  &amp;  \\<br>      &amp; 1 &amp; &amp; \\<br>    &amp;  &amp; \ddots &amp; \\<br>    &amp; &amp; &amp; 1<br>\end{pmatrix}\boldsymbol{Y}<br>$$</p>
<p>即每一维都是独立的正态分布 $\mathcal{N}(0, \sigma^2)$。但是 $S^2$ 全然不取决于 $Y_1 &#x3D; \bar{X}$，因此两者独立。与此同时，观察对角化后的二次型，我们同时证明了 $(n - 1)S^2 &#x2F; \sigma^2$ 服从 $t(n - 1)$。$\blacksquare$</p>
<blockquote>
<p><strong>Remark.</strong> 这似乎启发了我们证明平方和独立的一般方法？但是如果如果是要证明两个平方和独立，你可能就需要手搓一个坐标变换来让 $S_E$ 和 $S_A$ 分开。</p>
</blockquote>
<h1><span id="参数估计">参数估计</span></h1><p>在实际问题中，我们通常仅知道概率分布通常是一个参数化的分布 $F(x; \boldsymbol{\theta})$，其中 $\boldsymbol{\theta}\in \Theta$ 为一列参数。通常，在获取了容量为 $n$ 的样本 $X_1, …, X_n$，可以考虑设计统计量 $\hat{\boldsymbol{\theta}}(X_1, …, X_n)$ 来估计参数的取值。该统计量称作参数 $\boldsymbol{\theta}$ 的<strong>点估计量</strong>，代入具体样本数值后得到的称作参数的<strong>点估计值</strong>。</p>
<p>下文中，若不涉及样本容量，通常直接将 $\hat{\boldsymbol{\theta}}(X_1, …, X_n)$ 简称做 $\hat{\boldsymbol{\theta}}$。若不涉及多个参数，参数估计量将记作不加粗的 $\hat{\theta}$。</p>
<h2><span id="点估计的评价">点估计的评价</span></h2><p>评价参数估计的好坏，有以下角度：</p>
<div class="note "><p><strong>无偏性.</strong> 若估计量 $\hat{\theta}$ 满足 $\mathbb{E}[\hat{\theta}] &#x3D; \theta$，则称其为<em>无偏估计量</em>，否则称 $|\mathbb{E}[\hat{\theta}] - \theta|$ 为估计量的<em>偏差</em>。若 $\lim_{n\rightarrow \infty} \mathbb{E}[\hat{\theta}] &#x3D; \theta$，则称其为<em>渐进无偏估计量</em>。</p>
</div>

<p>容易验证以下事实：</p>
<ol>
<li>样本均值是总体均值的无偏估计，样本方差是总体方差的无偏估计，样本 $k$ 阶原点矩是总体 $k$ 阶原点矩的无偏估计。</li>
<li>二阶及以上的中心矩不是总体对应阶中心距的无偏估计。</li>
<li>无偏估计量的非线性函数一般不是对应参数的函数的无偏估计。</li>
</ol>
<div class="note "><p><strong>有效性.</strong> 直觉上，方差越小越有效。设 $\hat{\theta}_1, \hat{\theta}_2$ 是两个无偏估计量。若 $\forall \theta\in \Theta, D[\hat{\theta}_1] \leq D[\hat{\theta}_2]$，至少有一处不取等，则称 $\hat{\theta}_1$ 比 $\hat{\theta}_2$ <em>有效</em>。</p>
</div>

<div class="note "><p><strong>均方误差准则.</strong> 设 $\hat{\theta}$ 是 $\theta$ 的点估计，方差存在，则称 $\mathrm{MSE}(\hat{\theta}):&#x3D;\mathbb{E}[(\hat{\theta} - \theta)^2]$ 为估计量的<em>均方误差</em>。对于无偏估计，这个量恰是 $\hat{\theta}$ 的方差。</p>
</div>

<p>熟知参数估计的偏差和方差之间存在一个 trade-off，均方误差可谓是综合了两者的一个评判标准（注意均方误差实际上就是方差加上偏差的平方），因此在实践中有时更为重要。</p>
<div class="note "><p><strong>相合性.</strong> 设 $\hat{\theta}(X_1, …, X_n)$ 是参数 $\theta$ 的估计量。若对于任意的 $\theta\in\Theta$ 都有 $\hat{\theta}_n$ 依概率收敛于 $\theta$，则称 $\hat{\theta}$ 为 $\theta$ 的<em>相合估计</em>或者<em>一致估计</em>。</p>
</div>

<p>值得注意的是，相合估计可能甚至不是渐进无偏的（一个显然的反例是一个 $0$ 的估计量以 $1&#x2F;n$ 的概率取 $n$，其余时候取 $0$），但它能反映参数的估计量是在大样本下渐进收敛的。</p>
<p>另外，若 $\hat{\theta}$ 是 $\theta$ 的相合估计量，$g(x)$ 在 $\theta$ 处连续，则 $g(\hat{\theta})$ 是 $g(\theta)$ 的相合估计。这和无偏估计的情况有所不同。</p>
<div class="note "><p><strong>有效性.</strong> 若一个估计量的方差（渐进）达到了 <a href="../../../../2025/06/04/InformationTheoryIntuitions/#%E6%97%A0%E5%81%8F%E4%BC%B0%E8%AE%A1%E5%92%8C-cramer-rao-%E4%B8%8D%E7%AD%89%E5%BC%8F">Cramer-Rao 不等式</a> 给出的下界，则称其为<em>（渐进）有效估计</em>。</p>
</div>

<h2><span id="点估计的方法">点估计的方法</span></h2><p>接下来给出两种点估计参数的具体方法。</p>
<div class="note warning"><p><strong>矩估计法.</strong> 求出总体的前 $k$ 阶矩关于参数的函数，替之以样本的 $k$ 阶矩便可列出方程组，从而可解得参数的估计量。此处选用原点矩或中心矩均可。这称为样本的<em>矩估计</em>。</p>
</div>

<div class="note warning"><p><strong>极大似然估计.</strong> 假设总体 $X$ 服从参数化的分布 $f(x; \theta)$（其中 $f$ 为密度函数，若 $X$ 是连续随机变量；或为质量函数，若 $X$ 为离散随机变量），从中采出样本 $X_1, …, X_n$，其观察值为 $x_1, …, x_n$。似然函数定义为如下能够刻画观察到该样本的可能性的量：</p>
<p>$$<br>L(\theta) &#x3D; \prod_{i&#x3D;1}^n f(x_i; \theta)<br>$$</p>
<p>称 $\hat{\theta}(x_1, …, x_n) :&#x3D; \arg\max_{\theta\in \Theta} L(\theta)$ 为 $\theta$ 的<em>极大似然估计值</em>，相应统计量为<em>极大似然估计量</em>。</p>
</div>

<div class="note "><p><strong>正态分布的参数估计.</strong> 从参数化的正态分布 $\mathcal{N}(\mu, \sigma^2)$（$\mu, \sigma$ 均为参数）中采得样本 $X_1, …, X_n$，求 $\mu, \sigma$ 的矩估计和极大似然估计。</p>
</div>

<p>矩估计：</p>
<ol>
<li>熟知 $\mu &#x3D; \mathbb{E}[X], \sigma^2 &#x3D; \mathbb{E}[X] - \mathbb{E}[X^2]$，因此矩估计量可以为 $\hat{\mu} &#x3D; A_1, \hat{\sigma}_2 &#x3D; A_2 - A_1^2$；</li>
<li>熟知 $\mu &#x3D; \mathbb{E}[X], \sigma^2 &#x3D; D[X]$，因此矩估计量可以为 $\hat{\mu} &#x3D; A_1, \hat{\sigma}^2 &#x3D; B_1$。</li>
</ol>
<p>似然估计：最大化似然函数等价于最大化其对数，即</p>
<p>$$<br>\ln L(\theta) &#x3D; -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln \sigma^2 - \frac{1}{\sigma^2}\sum_{i&#x3D;1}^n (x_i - \mu)^2<br>$$</p>
<p>令 $\frac{\partial}{\partial \mu} \ln L &#x3D; \frac{\partial}{\partial \sigma^2} \ln L &#x3D; 0$ 便可算出 $\hat{\mu} &#x3D; \bar{x}, \hat{\sigma^2} &#x3D; \sum_{i&#x3D;1}^n (x_i - \bar{x})^2$。</p>
<p>可以发现最大似然估计对 $\sigma^2$ 的估计是有偏的。</p>
<p>作为操演，读者还可尝试计算均匀分布 $U[0, \theta]$ 的参数估计。结论是：</p>
<ul>
<li><strong>矩估计.</strong> $\hat{\theta} &#x3D; 2\bar{x}$；</li>
<li><strong>极大似然估计.</strong> $\hat{\theta} &#x3D; \max_{i&#x3D;1}^n x_i$。（这是因为 $L(\theta) &#x3D; \theta^n$，仅当 $\theta \geq \max x_i$）</li>
</ul>
<h2><span id="区间估计">区间估计</span></h2><div class="note success"><p><strong>定义 4（置信区间）.</strong> 设总体 $X$ 的分布函数为参数化的分布 $F(x; \theta)$，其中 $\theta$ 为参数。$X_1, …, X_n$ 是总体 $X$ 的一个样本，给定 $\alpha \in (0, 1)$，若两个统计量 $\hat{\theta}_L$ 和 $\hat{\theta}_R$ 满足</p>
<p>$$<br>\Pr\left[\hat{\theta}_L(X_1, …, X_n) &lt; \theta &lt; \hat{\theta}_R(X_1, …, X_n)\right] \geq 1 - \alpha, \qquad \forall \theta\in \Theta<br>$$</p>
<p>则随机区间 $(\hat{\theta}_L, \hat{\theta}_R)$ 称为参数 $\theta$ 的<em>双侧置信区间</em>；$1 - \alpha$ 称为<em>置信度</em>；$\hat{\theta}_L, \hat{\theta}_R$ 分别称为<em>双侧置信下限</em>和<em>双侧置信上限</em>。</p>
</div>

<div class="note success"><p><strong>定义 5（单侧置信限）.</strong> 若有</p>
<p>$$<br>\Pr\left[\hat{\theta}_L(X_1, …, X_n) &lt; \theta\right] \geq 1 - \alpha, \qquad \forall \theta\in \Theta<br>$$</p>
<p>则 $\hat{\theta}_L$ 称作 $\theta$ 的单侧置信下限，$(\hat{\theta}_L, \infty)$ 称作 $\theta$ 的置信度为 $1 - \alpha$ 的<em>单侧置信区间</em>。</p>
<p>类似地，可定义<em>单侧置信上限</em> $\hat{\theta}_R$ 和对应的单侧置信区间 $(-\infty, \hat{\theta}_R)$。</p>
</div>

<p>观察上述定义，容易想象这样一套计算方法：</p>
<div class="note warning"><p><strong>枢轴量法.</strong> </p>
<ol>
<li>构造一个参数化的统计量 $G(X_1, …, X_n; \theta)$，称作<em>枢轴量</em>，其服从某一易于计算的分布；</li>
<li>求 $(a, b)$ 使得 $\Pr[a &lt; G(X_1, …, X_n; \theta) &lt; b] &#x3D; 1 - \alpha$；</li>
<li>解不等式 $a &lt; G(X_1, …, X_n; \theta) &lt; b$，得出置信下限和置信上限。</li>
</ol>
</div>

<div class="note "><p><strong>伯努利分布的参数的区间估计.</strong> 设总体 $X$ 服从 $\mathrm{Bern}(p)$，$X_1, …, X_n$ 为采自 $X$ 的一系列样本。求参数 $p$ 的置信度为 $1 - \alpha$ 的双侧置信区间。</p>
</div>

<p>我们构造如下枢轴量，根据中心极限定理其近似服从标准正态分布：</p>
<p>$$<br>G(X_1, …, X_n; p) :&#x3D; \frac{\sum_{i&#x3D;1}^n X_i - np}{\sqrt{np(1 - p)}}<br>$$</p>
<p>于是可求出该枢轴量高概率属于的区间，这无非是 $(z_{-\alpha &#x2F; 2}, z_{\alpha &#x2F; 2})$。此后只需解不等式</p>
<p>$$<br>\left(\frac{n\bar{X} - np}{\sqrt{np(1 - p)}}\right)^2 \leq z_{\alpha &#x2F; 2}^2<br>$$</p>
<p>无非是一些琐碎的操作，且此分布也不属于考察的重点情况，因此细节留予读者。</p>
<div class="note "><p><strong>单个正态总体的期望区间估计.</strong> 总体 $X$ 服从正态分布 $\mathcal{N}(\mu, \sigma^2)$，从中采出 $n$ 个样本 $X_1, …, X_n$，在 $\sigma$ 已知 &#x2F; 未知的情况下讨论 $\mu$ 的置信区间如何计算，并讨论 $\sigma$ 的置信区间如何计算。</p>
</div>

<ul>
<li><p><strong>$\mu$ 的置信区间.</strong></p>
<ul>
<li><p><strong>$\sigma$ 已知.</strong> 定义枢轴量 </p>
<p>$$<br>G(X_1, …, X_n; \mu) :&#x3D; \frac{\sum_{i &#x3D; 1}^n X_i - n\mu}{\sqrt{n}\sigma}<br>$$</p>
<p>其服从正态分布，$(a, b) &#x3D; (-z_{\alpha &#x2F; 2}, z_{\alpha &#x2F; 2})$。容易反解出置信区间为</p>
<p>$$<br>\boxed{<br>\left(\bar{X} - \frac{\sigma}{\sqrt n}z_{\alpha &#x2F; 2}, \bar{X} + \frac{\sigma}{\sqrt n}z_{\alpha &#x2F; 2} \right)<br>}<br>$$</p>
</li>
<li><p><strong>$\sigma$ 未知.</strong> 定义枢轴量</p>
<p>$$<br>G(X_1, …, X_n; \mu) :&#x3D; \frac{\sum_{i&#x3D;1}^n X_i - n\mu}{\sqrt n S}<br>$$</p>
<p>其服从自由度为 $n - 1$ 的 $t$ 分布，$(a, b) &#x3D; (-t_{\alpha &#x2F; 2}(n - 1), t_{\alpha &#x2F; 2}(n - 1))$。容易反解出置信区间为</p>
<p>$$<br>\boxed{<br>\left(\bar{X} - \frac{S}{\sqrt n}t_{\alpha &#x2F; 2}(n - 1), \bar{X} + \frac{S}{\sqrt n}t_{\alpha &#x2F; 2}(n - 1)\right)<br>}<br>$$</p>
</li>
</ul>
</li>
<li><p><strong>$\sigma$ 的置信区间.</strong> 定义枢轴量</p>
<p>$$<br>G(X_1, …, X_n; \sigma) :&#x3D; \frac{(n - 1)S^2}{\sigma}<br>$$</p>
<p>其服从自由度为 $n - 1$ 的 $\chi^2$ 分布，$(a, b) &#x3D; (\chi^2_{\alpha &#x2F; 2}(n - 1), \chi^2_{1 - \alpha &#x2F; 2}(n - 1))$。容易反解出置信区间为 </p>
<p>$$<br>\boxed{<br>  \left(\frac{(n - 1)S^2}{\chi^2_{1 - \alpha &#x2F; 2}(n - 1)}, \frac{(n - 1)S^2}{\chi^2_{\alpha &#x2F; 2}(n - 1)}\right)<br>}<br>$$</p>
</li>
</ul>
<div class="note "><p><strong>两个正态总体的参数估计.</strong> 总体 $X \sim \mathcal{N}(\mu_1, \sigma_1^2), Y\sim \mathcal{N}(\mu_2, \sigma_2^2)$。从中各采出 $n_1$ 个样本 $X_1, …, X_{n_1}$ 和 $n_2$ 个样本 $Y_1, …, Y_{n_2}$，在 $\sigma$ 已知 &#x2F; 未知（仅考虑 $\sigma_1^2 &#x3D; \sigma_2^2 &#x3D; \sigma^2$）的情况下讨论 $\mu_1 - \mu_2$ 的置信区间如何计算，并讨论 $\sigma_1 &#x2F; \sigma_2$ 的置信区间如何计算。</p>
</div>

<ul>
<li><p><strong>$\mu_1 - \mu_2$ 的估计.</strong> </p>
<ul>
<li><p><strong>$\sigma$ 已知.</strong> 注意 $\bar{X} - \bar{Y}\sim \mathcal{N}\left(\mu_1 - \mu_2, \frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}\right)$，进而构造枢轴量 $\frac{\bar{X} - \bar{Y} - (\mu_1 - \mu_2)}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}$ 解得其置信区间为</p>
<p>$$<br>\boxed{<br>\left((\bar{X} - \bar{Y}) \pm z_{\alpha &#x2F; 2}\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\right)<br>}<br>$$</p>
</li>
<li><p><strong>$\sigma$ 未知.</strong> 定义 $S_w^2 &#x3D; \frac{(n_1 - 1)S_1^2 + (n_2 - 1)S_2^2}{n_1 + n_2 - 2}$，可知 $\frac{\bar{X} - \bar{Y} - (\mu_1 - \mu_2)}{S_w\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$ 服从自由度为 $n - 2$ 的 $t$ 分布。解得其置信区间为</p>
<p>$$<br>\boxed{<br>\left((\bar{X} - \bar{Y}) \pm t_{\alpha &#x2F; 2}(n_1 + n_2 - 2)S_w\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\right)<br>}<br>$$</p>
</li>
</ul>
</li>
<li><p><strong>$\sigma_1 &#x2F; \sigma_2$ 的估计.</strong> 显然 $\frac{S_1^2 &#x2F; S_2^2}{\sigma_1 &#x2F; \sigma_2}$ 服从自由度为 $(n_1 - 1, n_2 - 1)$ 的 $F$ 分布，解得置信区间为 </p>
<p>$$<br>\boxed{<br>  \left(\frac{S_1^2}{S_2^2}\cdot \frac{1}{F_{\alpha &#x2F; 2}(n_1 - 1, n_2 - 1)}, \frac{S_1^2}{S_2^2}\cdot \frac{1}{F_{1 - \alpha &#x2F; 2}(n_1 - 1, n_2 - 1)}\right)<br>}<br>$$</p>
</li>
</ul>
<h1><span id="假设检验">假设检验</span></h1><p>论证假设是否<strong>不合理</strong>。本节围绕如下实例展开：</p>
<div class="note "><p><strong>一个双边检验的例子.</strong> 一个总体 $X$ 照以往经验服从 $\mathcal{N}(6.0, 0.36)$，现又从中采出了 $10$ 个样本，得其均值为 $6.4$。在显著水平 $0.05$ 下检验均值较以往是否有明显变化。</p>
</div>

<ul>
<li><strong>假设.</strong> 关于未知分布的假设；</li>
<li><strong>原假设 $H_0$.</strong> 希望证否的假设；</li>
<li><strong>备择假设 $H_1$.</strong> 与原假设对立的假设；</li>
<li><strong>参数检验.</strong> 已知总体的形式，望检验关于未知参数的假设：<ul>
<li>$H_0: \theta \geq \theta_0, H_1 : \theta &lt; \theta_0$ <strong>（左边检验）</strong>；</li>
<li>$H_0: \theta \leq \theta_0, H_1 : \theta &gt; \theta_0$ <strong>（右边检验）</strong>；</li>
<li>$H_0: \theta &#x3D; \theta_0, H_1 : \theta\ne \theta_0$ <strong>（双边检验）</strong>；</li>
</ul>
</li>
<li><strong>非参数检验.</strong> 总体分布未知，对总体的分布或数字特征进行假设检验。</li>
<li><strong>检验规则.</strong> 将样本空间划分为两个对立的集合 $W, \bar{W}$，当 $(x_1, …, x_n)\in W$，拒绝原假设。此处 $W$ 称作<em>拒绝域</em>。为了方便地表示 $W$，可构造统计量 $T(x_1, …, x_n)$，拒绝原假设当且仅当 $T\in C$。</li>
</ul>
<p>在上述例子中，可构造统计量 $\bar{X}$，当 $\bar{X}$ 和原均值（$|\bar{X} - 6.0| \geq C$）偏差过大时拒绝假设。</p>
<p>注意在分布非平凡的情况下，都可能会出现错误的判断。错误有两类：</p>
<ul>
<li><strong>第 I 类错误.</strong> 拒绝真实的原假设。其概率为 $\Pr[\text{reject $H_0$} | \text{$H_0$ is true}]$；</li>
<li><strong>第 II 类错误.</strong> 接受错误的原假设。其概率为 $\Pr[\text{accept $H_0$} | \text{$H_0$ is false}]$。</li>
</ul>
<p>总样本量（或更显然地，总错误率）一定的情况下，这两类错误的错误率是拮抗的。因为我们的首要目标是证否原假设（希望拒绝的尽量都是错的），所以偏好使第 I 类错误概率降低。</p>
<p>例子中：</p>
<ul>
<li>犯第 I 类错误的概率为 $2 - 2\Phi\left(\frac{C}{\sigma &#x2F; \sqrt n}\right)$（$\Phi$ 为标准正态分布函数）。</li>
<li>犯第 II 类错误的概率为 $\Phi\left(\frac{6.0 + C - \mu}{\sigma &#x2F; \sqrt n}\right) - \Phi\left(\frac{6.0 - C - \mu}{\sigma &#x2F; \sqrt n}\right)$。（$\mu \ne 6.0$）</li>
</ul>
<p>简单讨论可知在调大 $C$ 时，第 I 类错误概率将降低，同时无论 $\mu$ 几何第二类错误的概率都将升高，其上确界恰好与第 I 类错误互补。</p>
<div class="note success"><p><strong>定义 1（Neyman-Pearson 原则）.</strong> 取 $\alpha \in (0, 1)$，寻求检验规则使得发生第 I 类错误的概率不超过 $\alpha$，同时最小化第 II 类错误发生的概率。$\alpha$ 称为显著水平。</p>
</div>

<p>根据此原则，应当取 $C &#x3D; z_{\alpha &#x2F; 2}\sigma &#x2F; \sqrt n &#x3D; 0.392$，因此拒绝原假设。</p>
<p>在 Neyman-Pearson 原则上定义的一个方便的上层建筑是 $p$ 值。</p>
<div class="note success"><p><strong>定义 2（$p$ 值）.</strong> 原假设成立时，检验统计量取比观察到的结果更为极端的数值的概率。</p>
<p>若 $p \leq \alpha$，拒绝原假设，称检验结果在水平 $\alpha$ 下是<em>统计显著</em>的。</p>
<p>若 $p &gt; \alpha$，接受原假设，称检验结果在水平 $\alpha$ 下是<em>统计不显著</em>的。</p>
</div>

<p>例子的 $p$ 值为 $\Pr_{H_0}[|\bar{X} - 6.0| \geq 0.4] &#x3D; 2 - 2\Phi(2) &#x3D; 0.046$。应当拒绝。</p>
<hr>
<p>关于单个正态总体的假设检验，两个正太总体的假设检验，在前述工具的基础之上，无非还是上一节那一套东西，这里略过。结论一并写在附录当中。</p>
<p>当然，这也揭示了如下的关系（据两个问题的定义显而易见）：</p>
<ol>
<li>一般地，假设检验问题 $H_0 : \theta &#x3D; \theta_0, H_1 : \theta \ne \theta_0$ 的显著水平为 $\alpha$ 的接受域能写作 $\hat{\theta}_L &lt; \theta_0 &lt; \hat{\theta}_U$，则 $(\hat{\theta}_L, \hat{\theta}_U)$ 正好是 $\theta$ 的置信水平为 $1 - \alpha$ 的置信区间。反之，若 $(\hat{\theta}_L, \hat{\theta}_U)$ 是 $\theta$ 的置信水平为 $1 - \alpha$ 的置信区间，则令拒绝域为 $\theta_0 \leq \hat{\theta}_L$ 或 $\theta_0 \geq \hat{\theta}_U$ 可得显著水平为 $\alpha$ 的双边检验拒绝域。</li>
<li>同理，左边检验对应单侧置信上限；右边检验对应单侧置信下限。</li>
</ol>
<hr>
<p>以上内容都是参数化检验。下面是一个经典的非参数检验问题：</p>
<div class="note "><p><strong>拟合优度检验.</strong> $F(x)$ 是总体 $x$ 的未知的分布函数，$F_0(x)$ 是已知但是可能含有若干参数的分布函数，检验假设</p>
<p>$$<br>H_0 : F(x) &#x3D; F_0(x) \forall x\in \mathbb{R}<br>$$</p>
</div>

<p>想要做这个问题，唯一可以想象的方法是首先将值域离散化，然后考察真实频率和所期待频率之偏差。由此动机推出 Pearson $\chi^2$ 检验：</p>
<div class="note warning"><p><strong>Pearson $\chi^2$ 检验.</strong></p>
<ol>
<li><p>将总体 $X$ 的取值范围划分作 $k$ 个互不相交的子集 $\mathcal{X} &#x3D; \sqcup_{i&#x3D;1}^k A_k$；</p>
</li>
<li><p>记 $n_i$ 表示落在 $A_i$ 中的频数。</p>
</li>
<li><p>若 $F_0(x)$ 不带参数，直接取 $p_i &#x3D; \Pr[X\in A_i]$。若 $F_0(x)$ 带若干参数，先用极大似然估计来估计参数，然后可求得 $p_i$ 的估计值 $\hat{p}_i$。</p>
</li>
<li><p>取统计量</p>
<p>$$<br>\chi^2 &#x3D; \sum_{i&#x3D;1}^{k}\frac{(n_i - np_i)^2}{np_i} &#x3D; \sum_{i&#x3D;1}^k \frac{n_i^2}{np_i} - n<br>$$</p>
<p>该统计量刻画了分布与理论分布的差值。理应较小。拒绝域形如 $\chi^2 \geq c$。</p>
</li>
</ol>
</div>

<p>关于该检验的结论：当 $n$ 充分大时，$H_0$ 为真时，$\chi^2$ 近似服从 $\chi^2(k - r - 1)$，其中 $k$ 为分类数，$r$ 为参数数。</p>
<p>不会证。先摆了。</p>
<h1><span id="方差分析">方差分析</span></h1><ul>
<li><strong>试验指标.</strong> 研究对象的某个特征值（如某产品的使用寿命）；</li>
<li><strong>因素.</strong> 对试验指标产生影响的原因（如其工况的温度）；</li>
<li><strong>水平.</strong> 因素的不同状态（如常温、高温，etc）。</li>
</ul>
<div class="note "><p><strong>单因素方差分析.</strong> 一个单因素、$r$ 个水平，每个水平采样了 $n_j$ 个样本的单因素方差分析问题可抽象成如下数学模型</p>
<p>$$<br>\begin{aligned}<br>    &amp;X_{ij} &#x3D; \mu + \delta_j + \varepsilon_{ij} \\<br>    &amp;\varepsilon_{ij} \text{ i.i.d } \sim \mathcal{N}(0, \sigma^2) \\<br>    &amp;i &#x3D; 1, 2, …, n_j, j &#x3D; 1, 2, …, r<br>\end{aligned}<br>$$</p>
<p>其中 $\mu$ 为总平均，因此须满足 $\sum_{j&#x3D;1}^r n_j\delta_j &#x3D; 0$</p>
<p>检验假设 $H_0: \delta_1 &#x3D; \cdots &#x3D; \delta_r &#x3D; 0$，$H_1$ 为其反面。</p>
</div>

<p>可从上述问题中抽出三个统计量：</p>
<ol>
<li><strong>总偏差平方和.</strong> $S_T &#x3D; \sum_{j &#x3D; 1}^r\sum_{i &#x3D; 1}^{n_j}(X_{ij} - \bar{X})^2$；</li>
<li><strong>效应平方和.</strong> $S_A &#x3D; \sum_{j&#x3D;1}^r n_j(\bar{X}_{\cdot j} - \bar{X})^2$；</li>
<li><strong>误差平方和.</strong> $S_E &#x3D; \sum_{j&#x3D;1}^r \sum_{j&#x3D;1}^{n_j}(X_{ij} - \bar{X}_{\cdot j})^2$。</li>
</ol>
<p>直觉上讲，效应平方和刻画了不同水平引起的误差，误差平方和刻画了随机数引起的误差。在假设成立的条件下，其理应相差无几。为了推导最后需要的统计量，需要准备如下事实：</p>
<div class="note info"><p><strong>事实 1.</strong> $S_T &#x3D; S_A + S_E$。</p>
</div>

<p><strong>证明.</strong> 核心是注意到</p>
<p>$$<br>\begin{aligned}<br>    \sum_{j&#x3D;1}^r\sum_{i&#x3D;1}^{n_j}(X_{ij} - \bar{X}_{\cdot j})(\bar{X}_{\cdot j} - \bar{X}) &#x3D; \sum_{j&#x3D;1}^r(X_{ij} - \bar{X}_{\cdot j})\sum_{i&#x3D;1}^{n_j}(\bar{X}_{\cdot j} - \bar{X}) &#x3D; 0<br>\end{aligned}<br>$$</p>
<p>然后只需要拆一下那个二次函数即可。$\blacksquare$</p>
<div class="note info"><p><strong>事实 2.</strong> 三种偏差的期望：</p>
<p>$$<br>\begin{aligned}<br>    \mathbb{E}[S_T] &amp;&#x3D; \sum_{j&#x3D;1}^r n_j\delta_j^2 + (n - 1)\sigma^2 \\<br>    \mathbb{E}[S_A] &amp;&#x3D; \sum_{j&#x3D;1}^r n_j\delta_j^2 + (r - 1)\sigma^2 \\<br>    \mathbb{E}[S_E] &amp;&#x3D; (n - r)\sigma^2<br>\end{aligned}<br>$$</p>
</div>

<p><strong>证明.</strong> 只算两个</p>
<p>$$<br>\begin{aligned}<br>    \mathbb{E}[S_T] &amp;&#x3D; \sum_{j&#x3D;1}^r\sum_{i&#x3D;1}^{n_j} \mathbb{E}[X_{ij}^2] - n \mathbb{E}[\bar{X}^2] \\<br>                    &amp;&#x3D; \sum_{j&#x3D;1}^r\sum_{i&#x3D;1}^{n_j} \left((\mu + \delta_i)^2 + \sigma^2\right) - n \left( \frac{\sigma^2}{n} + \left(\mu + \frac{1}{n}\sum_{j&#x3D;1}^n n_j\delta_j\right)^2\right) \\<br>                    &amp;&#x3D; \sum_{j&#x3D;1}^r n_j\delta_j^2 + (n - 1)\sigma^2 \\<br>    \mathbb{E}[S_E] &amp;&#x3D; \sum_{j&#x3D;1}^r (n_j - 1)\sigma^2 \\<br>                    &amp;&#x3D; (n - r)\sigma^2<br>\end{aligned}<br>$$</p>
<p>结合事实 1 得到 $\mathbb{E}[S_A]$。$\blacksquare$ </p>
<div class="note info"><p><strong>事实 3.</strong> 当 $H_0$ 成立时，$S_A &#x2F; \sigma^2\sim \chi^2(r - 1), S_E &#x2F; \sigma^2\sim \chi^2(n - r)$，且相互独立。</p>
</div>

<p><strong>证明.</strong> $\color{red}{\text{Sorry.}}$</p>
<p>定义统计量</p>
<p>$$<br>F &#x3D; \frac{S_A &#x2F; (r - 1)}{S_E &#x2F; (n - r)}<br>$$</p>
<p>它服从自由度为 $(r - 1, n - r)$ 的 $F$ 分布。当 $F &gt; F_{\alpha}(r - 1, n - r)$ 时拒绝原假设。</p>
<h1><span id="回归分析">回归分析</span></h1><div class="note "><p><strong>一元线性回归.</strong> 对 $x$ 的一组不全相同的值，得到样本 $(x_1, Y_1), (x_2, Y_2), …, (x_n, Y_n)$。一元线性回归模型为</p>
<p>$$<br>\begin{aligned}<br>    &amp; Y_i &#x3D; \alpha + \beta x_i + \varepsilon_i, \quad i &#x3D; 1, 2, …, n \\<br>    &amp; \varepsilon_i \text{ i.i.d } \sim \mathcal{N}(0, \sigma^2)<br>\end{aligned}<br>$$</p>
<p>其中 $\alpha, \beta, \sigma^2$ 均是未知的参数。</p>
</div>

<p>注意到这是一个参数估计问题。我们用最小二乘法来估计这两个参数。定义偏差</p>
<p>$$<br>Q(\alpha, \beta) :&#x3D; \sum_{i&#x3D;1}^n (y_i - \beta x_i - \alpha)^2<br>$$</p>
<p>直觉上这刻画了拟合的效果。因此我们将 $\hat{a}, \hat{b}$ 取作将其最小化的参数。我们使用多元微积分来解此问题</p>
<p>$$<br>\begin{aligned}<br>    \frac{\partial Q}{\partial \alpha} &#x3D; 0 &amp; \Rightarrow \bar{y} - \beta \bar{x} - \alpha &#x3D; 0 \\<br>    \frac{\partial Q}{\partial \beta} &#x3D; 0 &amp; \Rightarrow \bar{x}\alpha + \bar{x^2}\beta &#x3D; \bar{xy}<br>\end{aligned}<br>$$</p>
<p>此方程称作<strong>正规方程</strong>，其解即为一元线性回归中对 $\alpha, \beta$ 的估计值 $\hat{\alpha}, \hat{\beta}$。式子中出现的诸统计量及相关资料定义如下：</p>
<p>$$<br>\begin{aligned}<br>    &amp;\bar{x} &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n x_i, \quad \bar{y} &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n y_i \\<br>    &amp;s_{xx} &#x3D; \sum_{i&#x3D;1}^n (x_i - \bar{x})^2, \quad s_{xy} &#x3D; \sum_{i&#x3D;1}^n (x_i - \bar{x})(y_i - \bar{y}), \quad s_{yy} &#x3D; \sum_{i&#x3D;1}^n (y_i - \bar{y})^2 \\<br>    &amp;\bar{x^2} &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n x_i^2, \quad \bar{xy} &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n x_iy_i, \quad \bar{y^2} &#x3D; \frac{1}{n}\sum_{i&#x3D;1}^n y_i^2<br>\end{aligned}<br>$$</p>
<p>整理得到正规方程的解可以简便地表示作</p>
<p>$$<br>\begin{cases}<br>    \hat{\alpha} &#x3D; \bar{y} - \hat{\beta}\bar{x} \\<br>    \hat{\beta} &#x3D; \frac{s_{xy}}{s_{xx}}<br>\end{cases}<br>$$</p>
<blockquote>
<p><strong>Remark.</strong> 计算发现最小二乘法的目标和最大似然估计的目标不谋而合。</p>
</blockquote>
<div class="note info"><p><strong>事实 1.</strong> $\hat{\alpha}, \hat{beta}$ 服从正态分布。关于其期望和方差，有如下论断：$\hat{\alpha}, \hat{\beta}$ 分别是 $\alpha, \beta$ 的无偏估计，$D\left[\hat{\alpha}\right] &#x3D; \left(\frac{1}{n} + \frac{\bar{x^2}}{s_xx}\right)\sigma^2, D\left[\hat{\beta}\right] &#x3D; \frac{\sigma^2}{s_{xx}}$。</p>
</div>

<p><strong>证明.</strong> 琐碎计算。$\blacksquare$</p>
<div class="note info"><p><strong>事实 2.</strong> 定义<em>残差</em> $e_i &#x3D; y_i - \hat{y}_i$。则可以用残差平方和估计 $\sigma^2$：如下的量是 $\sigma^2$ 的无偏估计</p>
<p>$$<br>s^2 &#x3D; \frac{1}{n - 2}\sum_{i&#x3D;1}^n (y_i - \hat{y}_i)^2 &#x3D; \frac{s_{yy} - \hat{\beta}s_{xy}}{n - 2}<br>$$</p>
</div>

<p><strong>证明.</strong> 核心只在于验证 $\mathbb{E}[s_{yy}] &#x3D; (n - 1)\sigma^2 + \beta^2 s_{xx}$。琐碎计算。$\blacksquare$</p>
<hr>
<p>可以检验回归分析的显著性。将其抽象成如下假设检验问题：</p>
<p>$$<br>H_0 : \beta &#x3D; 0, H_1 : \beta\ne 0<br>$$</p>
<p>此时可仿照方差分析抽出 3 个统计量：</p>
<ol>
<li><strong>总平方和.</strong> $SST :&#x3D; \sum (y_i - \bar{y})^2$；</li>
<li><strong>残差平方和.</strong> $SSE :&#x3D; \sum (y_i - \hat{y}_i)^2$；</li>
<li><strong>回归平方和.</strong> $SSR :&#x3D; \sum (\hat{y}_i - \bar{y})^2$。</li>
</ol>
<div class="note info"><p><strong>事实 3.</strong> $SST &#x3D; SSE + SSR$。</p>
</div>

<p><strong>证明.</strong> 琐碎计算。$\blacksquare$</p>
<div class="note info"><p><strong>事实 4.</strong> $\frac{SSE}{\sigma^2} \sim \chi^2(n - 2), \frac{SSR}{\sigma^2} \sim \chi^2(1)$，且相互独立。</p>
</div>

<p><strong>证明.</strong> $\color{red}{\text{Sorry.}}$</p>
<p>据此定义统计量</p>
<p>$$<br>F :&#x3D; \frac{SSR &#x2F; 1}{SSE &#x2F; (n - 2)}<br>$$</p>
<p>其服从 $F(1, n - 2)$。拒绝域为 $W &#x3D; \{F &gt; F_{\alpha}(1, n - 2)\}$。</p>
<h1><span id="附录统计常用速查表格">附录：统计常用速查表格</span></h1><p><strong>表 1. 正态总体区间估计相关</strong> 上面三行为单个正态总体，下面三行为两个正态总体，置信水平为 $\alpha$。</p>
<table>
<thead>
<tr>
<th align="center"><strong>待估参数</strong></th>
<th align="center"><strong>其他参数</strong></th>
<th align="center"><strong>枢轴量</strong></th>
<th align="center"><strong>分布</strong></th>
<th align="center"><strong>置信区间</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">$\mu$</td>
<td align="center">$\sigma$ 已知</td>
<td align="center">$\frac{\bar{X} - \mu}{\sigma &#x2F; \sqrt n}$</td>
<td align="center">$\mathcal{N}(0, 1)$</td>
<td align="center">$\left(\bar{X} \pm \frac{\sigma}{\sqrt n}z_{\alpha &#x2F; 2}\right)$</td>
</tr>
<tr>
<td align="center">$\mu$</td>
<td align="center">$\sigma$ 未知</td>
<td align="center">$\frac{\bar{X} - \mu}{S &#x2F; \sqrt n}$</td>
<td align="center">$t(n - 1)$</td>
<td align="center">$\left(\bar{X} \pm \frac{S}{\sqrt n}t_{\alpha &#x2F; 2}(n - 1)\right)$</td>
</tr>
<tr>
<td align="center">$\sigma$</td>
<td align="center">$\mu$ 未知</td>
<td align="center">$\frac{(n - 1)S^2}{\sigma^2}$</td>
<td align="center">$\chi^2(n - 1)$</td>
<td align="center">$\left(\frac{(n - 1)S^2}{\chi^2_{1 - \alpha &#x2F; 2}(n - 1)}, \frac{(n - 1)S^2}{\chi^2_{\alpha &#x2F; 2}(n - 1)}\right)$</td>
</tr>
<tr>
<td align="center">$\mu_1\!-\!\mu_2$</td>
<td align="center">$\sigma$ 已知</td>
<td align="center">$\frac{\bar{X} - \bar{Y} - (\mu_1 - \mu_2)}{\sigma\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$</td>
<td align="center">$\mathcal{N}(0, 1)$</td>
<td align="center">$\left((\bar{X} - \bar{Y}) \pm z_{\alpha &#x2F; 2}\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}\right)$</td>
</tr>
<tr>
<td align="center">$\mu_1\!-\!\mu_2$</td>
<td align="center">$\sigma$ 未知</td>
<td align="center">$\frac{\bar{X}- \bar{Y} - (\mu_1 - \mu_2)}{S_w\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$</td>
<td align="center">$t(n_1\!+\!n_2\!-\!2)$</td>
<td align="center">$\begin{pmatrix}((\bar{X}\!-\!\bar{Y})\!\pm\!\\t_{\alpha &#x2F; 2}(n_1\!\!+\!\!n_2\!\!-\!\!2)S_w\sqrt{\frac{1}{n_1}\!+\!\frac{1}{n_2}}\end{pmatrix}$</td>
</tr>
<tr>
<td align="center">$\sigma_1 &#x2F; \sigma_2$</td>
<td align="center">$\mu$ 未知</td>
<td align="center">$\frac{S_1^2 &#x2F; \sigma_1^2}{S_2^2 &#x2F; \sigma_2^2}$</td>
<td align="center">$F(n_1\!-\!1,\!n_2\!-\!1)$</td>
<td align="center">$\begin{pmatrix}\frac{S_1^2}{S_2^2} \frac{1}{F_{\alpha &#x2F; 2}(n_1 - 1, n_2 - 1)},\\ \frac{S_1^2}{S_2^2} \frac{1}{F_{1 - \alpha &#x2F; 2}(n_1 - 1, n_2 - 1)}\end{pmatrix}$</td>
</tr>
</tbody></table>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Probability-Theory/" rel="tag"># Probability Theory</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/06/04/AlgorithmAnalysis/" rel="prev" title="算法设计与分析（实验班）复习笔记">
                  <i class="fa fa-angle-left"></i> 算法设计与分析（实验班）复习笔记
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/06/14/TCSRevision/" rel="next" title="Revision | 计算理论导论">
                  Revision | 计算理论导论 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">King Strange</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
